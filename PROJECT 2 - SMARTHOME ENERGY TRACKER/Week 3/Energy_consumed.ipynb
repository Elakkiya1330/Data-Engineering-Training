{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Load a large dataset of sensor logs using PySpark"
      ],
      "metadata": {
        "id": "TZKVRlhG-7Q5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lHjFhur96P8",
        "outputId": "6e9cea17-a557-4616-c6c0-27c29b9d7b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# I have the the cleaned data from python(week2) in drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"SmartHomeEnergyAnalysis\").getOrCreate()"
      ],
      "metadata": {
        "id": "kPrVPa-B-fmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('/content/drive/My Drive/cleaned_energy_logs.csv', header=True, inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FclGFUg-raV",
        "outputId": "4b33febe-b467-4f71-846c-e1ff0a369867"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---------------+-------------------+\n",
            "|log_id|device_id|energy_used_kwh|           log_time|\n",
            "+------+---------+---------------+-------------------+\n",
            "|     1|      101|            2.5|2025-07-20 09:00:00|\n",
            "|     2|      101|            3.0|2025-07-20 18:00:00|\n",
            "|     3|      102|            1.2|2025-07-20 12:00:00|\n",
            "|     4|      103|            0.0|2025-07-20 13:00:00|\n",
            "|     5|      104|            4.5|2025-07-20 07:00:00|\n",
            "|     6|      104|            5.0|2025-07-20 20:00:00|\n",
            "|     7|      105|            1.8|2025-07-20 10:00:00|\n",
            "+------+---------+---------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Group by device and calculate peak vs off-peak usage"
      ],
      "metadata": {
        "id": "yVKab0WM-93B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, hour\n",
        "df = df.withColumn(\"hour\", hour(col(\"log_time\")))\n",
        "# here the values i have given for peak and offpeak hr is just a example value based on my data\n",
        "peak_df = df.filter((col(\"hour\") > 11) & (col(\"hour\") <= 20))\n",
        "off_peak_df = df.filter((col(\"hour\") >= 0) & (col(\"hour\") <= 10))"
      ],
      "metadata": {
        "id": "CdhPcztG-2ie"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# peak and offpeak usage\n",
        "from pyspark.sql.functions import max, avg\n",
        "peak_usage = peak_df.groupBy(\"device_id\").agg(max(\"energy_used_kwh\").alias(\"energy_used_peak_hr\"))\n",
        "peak_usage.show()\n",
        "off_peak_usage = off_peak_df.groupBy(\"device_id\").agg(max(\"energy_used_kwh\").alias(\"energy_used_offpeak_hr\"))\n",
        "off_peak_usage.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAYRLxj7AXL6",
        "outputId": "21bcf7ab-b627-42ec-805a-49708b58218e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+\n",
            "|device_id|energy_used_peak_hr|\n",
            "+---------+-------------------+\n",
            "|      101|                3.0|\n",
            "|      103|                0.0|\n",
            "|      102|                1.2|\n",
            "|      104|                5.0|\n",
            "+---------+-------------------+\n",
            "\n",
            "+---------+----------------------+\n",
            "|device_id|energy_used_offpeak_hr|\n",
            "+---------+----------------------+\n",
            "|      101|                   2.5|\n",
            "|      105|                   1.8|\n",
            "|      104|                   4.5|\n",
            "+---------+----------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identify top energy-consuming devices"
      ],
      "metadata": {
        "id": "Kirl_jYNBbMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "usage_summary = peak_usage.join(off_peak_usage, \"device_id\", \"outer\").na.fill(0)\n",
        "total_usage = df.groupBy(\"device_id\").agg(avg(\"energy_used_kwh\").alias(\"avg_energy\"),max(\"energy_used_kwh\").alias(\"max_energy\"))\n",
        "final_summary = usage_summary.join(total_usage, \"device_id\")\n",
        "top_devices = final_summary.orderBy(desc(\"max_energy\")).limit(5)\n",
        "top_devices.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FukabbmGBa27",
        "outputId": "c81fbc8c-e424-4305-9bd9-1b857cfa965e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+----------------------+----------+----------+\n",
            "|device_id|energy_used_peak_hr|energy_used_offpeak_hr|avg_energy|max_energy|\n",
            "+---------+-------------------+----------------------+----------+----------+\n",
            "|      104|                5.0|                   4.5|      4.75|       5.0|\n",
            "|      101|                3.0|                   2.5|      2.75|       3.0|\n",
            "|      105|                0.0|                   1.8|       1.8|       1.8|\n",
            "|      102|                1.2|                   0.0|       1.2|       1.2|\n",
            "|      103|                0.0|                   0.0|       0.0|       0.0|\n",
            "+---------+-------------------+----------------------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# i am saving the top_devices and their energy consumption during peak and offpeak hrs  as csv in drive\n",
        "# but it creates a folder in name of top_devices_output.csv and store the csv inside the folder not a direct csv file\n",
        "top_devices.coalesce(1).write.csv(\"/content/drive/My Drive/top_devices_output\", header=True, mode = 'overwrite')"
      ],
      "metadata": {
        "id": "IYOei2C0I3z-"
      },
      "execution_count": 40,
      "outputs": []
    }
  ]
}