{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Module 1: Setup & SparkSession Initialization"
      ],
      "metadata": {
        "id": "usdoUwskZDpu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g-7e9uPDWyU6"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"BotCampus PySpark Practice\").master(\"local[*]\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    (\"Anjali\", \"Bangalore\", 24),\n",
        "    (\"Ravi\", \"Hyderabad\", 28),\n",
        "    (\"Kavya\", \"Delhi\", 22),\n",
        "    (\"Meena\", \"Chennai\", 25),\n",
        "    (\"Arjun\", \"Mumbai\", 30)\n",
        "]\n",
        "columns = [\"name\", \"city\", \"age\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulp1HN8QYZnM",
        "outputId": "d2bf66ff-383d-450a-d333-2c53aca8c0e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+---------+---+\n",
            "|  name|     city|age|\n",
            "+------+---------+---+\n",
            "|Anjali|Bangalore| 24|\n",
            "|  Ravi|Hyderabad| 28|\n",
            "| Kavya|    Delhi| 22|\n",
            "| Meena|  Chennai| 25|\n",
            "| Arjun|   Mumbai| 30|\n",
            "+------+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show schema, explain data types, and convert to RDD.\n",
        "df.printSchema()\n",
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF7qeUklYxS9",
        "outputId": "10999c88-2fa9-4e91-8705-2ff3c81ad4bd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- city: string (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('name', 'string'), ('city', 'string'), ('age', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = df.rdd"
      ],
      "metadata": {
        "id": "Z_jH4vJAZCCY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print .collect() and df.rdd.map() output.\n",
        "print(df.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_dsonueZJad",
        "outputId": "bcfe1d8e-dd8c-4a22-f4b1-60db1abf3774"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Row(name='Anjali', city='Bangalore', age=24), Row(name='Ravi', city='Hyderabad', age=28), Row(name='Kavya', city='Delhi', age=22), Row(name='Meena', city='Chennai', age=25), Row(name='Arjun', city='Mumbai', age=30)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_rdd = df.rdd.map(lambda row: (row.name, row.age + 1))\n",
        "print(mapped_rdd.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtBC2svVZXiT",
        "outputId": "d640a1c3-79bc-47a7-bb20-ce992cb95931"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Anjali', 25), ('Ravi', 29), ('Kavya', 23), ('Meena', 26), ('Arjun', 31)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 2: RDDs & Transformations"
      ],
      "metadata": {
        "id": "U6uHhBMqZG8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = spark.sparkContext.parallelize([\n",
        "\"Ravi from Bangalore loved the delivery\",\n",
        "\"Meena from Hyderabad had a late order\",\n",
        "\"Ajay from Pune liked the service\",\n",
        "\"Anjali from Delhi faced UI issues\",\n",
        "\"Rohit from Mumbai gave positive feedback\"\n",
        "])"
      ],
      "metadata": {
        "id": "wiXpgOTmZ2vu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split each line into words ( flatMap ).\n",
        "words = feedback.flatMap(lambda line: line.split())\n",
        "words.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frOyvulYaJMq",
        "outputId": "6d760d0b-24d2-47a5-eedc-73a2edc614e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ravi',\n",
              " 'from',\n",
              " 'Bangalore',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'delivery',\n",
              " 'Meena',\n",
              " 'from',\n",
              " 'Hyderabad',\n",
              " 'had',\n",
              " 'a',\n",
              " 'late',\n",
              " 'order',\n",
              " 'Ajay',\n",
              " 'from',\n",
              " 'Pune',\n",
              " 'liked',\n",
              " 'the',\n",
              " 'service',\n",
              " 'Anjali',\n",
              " 'from',\n",
              " 'Delhi',\n",
              " 'faced',\n",
              " 'UI',\n",
              " 'issues',\n",
              " 'Rohit',\n",
              " 'from',\n",
              " 'Mumbai',\n",
              " 'gave',\n",
              " 'positive',\n",
              " 'feedback']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove stop words ( from , the , etc.).\n",
        "stop_words = {\"from\", \"with\", \"the\", \"an\", \"and\", \"had\", \"gave\"}\n",
        "filtered_words = feedback.flatMap(lambda line: line.lower().split()).filter(lambda w: w not in stop_words)\n",
        "print(filtered_words.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXG1cGeUbHws",
        "outputId": "1cb58848-3586-4cb8-8159-3d91926dc13f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ravi', 'bangalore', 'loved', 'delivery', 'meena', 'hyderabad', 'a', 'late', 'order', 'ajay', 'pune', 'liked', 'service', 'anjali', 'delhi', 'faced', 'ui', 'issues', 'rohit', 'mumbai', 'positive', 'feedback']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count each word frequency using reduceByKey\n",
        "word_count = words.map(lambda w: (w.lower(), 1)).reduceByKey(lambda a, b: a + b)\n",
        "word_count.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kAZrELzbZIG",
        "outputId": "d5ddaa33-4b68-4d07-cddb-abafb7a4ec77"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('from', 5),\n",
              " ('loved', 1),\n",
              " ('liked', 1),\n",
              " ('service', 1),\n",
              " ('anjali', 1),\n",
              " ('faced', 1),\n",
              " ('issues', 1),\n",
              " ('rohit', 1),\n",
              " ('mumbai', 1),\n",
              " ('positive', 1),\n",
              " ('feedback', 1),\n",
              " ('ravi', 1),\n",
              " ('bangalore', 1),\n",
              " ('the', 2),\n",
              " ('delivery', 1),\n",
              " ('meena', 1),\n",
              " ('hyderabad', 1),\n",
              " ('had', 1),\n",
              " ('a', 1),\n",
              " ('late', 1),\n",
              " ('order', 1),\n",
              " ('ajay', 1),\n",
              " ('pune', 1),\n",
              " ('delhi', 1),\n",
              " ('ui', 1),\n",
              " ('gave', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top 3 most frequent non-stop words.\n",
        "top3 = word_count.takeOrdered(3, key=lambda x: -x[1])\n",
        "print(\"Top 3 common words: \", top3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HcQf8xpbsds",
        "outputId": "2050e6e9-0dd3-4a47-a351-34466848a548"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 common words:  [('from', 5), ('the', 2), ('loved', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 3: DataFrames & Transformation (With Joins)"
      ],
      "metadata": {
        "id": "9X3SPxoIb5_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "\n",
        "students = [\n",
        "    (\"Amit\", \"10-A\", 89),\n",
        "    (\"Kavya\", \"10-B\", 92),\n",
        "    (\"Anjali\", \"10-A\", 78),\n",
        "    (\"Rohit\", \"10-B\", 85),\n",
        "    (\"Sneha\", \"10-C\", 80)\n",
        "]\n",
        "column1 = [\"name\", \"section\", \"marks\"]\n",
        "\n",
        "attendance = [\n",
        "    (\"Amit\", 24),\n",
        "    (\"Kavya\", 22),\n",
        "    (\"Anjali\", 20),\n",
        "    (\"Rohit\", 25),\n",
        "    (\"Sneha\", 19)\n",
        "]\n",
        "column2 = [\"name\", \"days_present\"]\n",
        "\n",
        "df_students = spark.createDataFrame(students, column1)\n",
        "df_attendance = spark.createDataFrame(attendance, column2)"
      ],
      "metadata": {
        "id": "eeRVsJhQb3jc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Join both DataFrames on name .\n",
        "df_joined = df_students.join(df_attendance, on=\"name\")\n",
        "df_joined.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsLWvPXgcRre",
        "outputId": "880f52f9-cfb0-49b8-ae58-14629d55d34f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+\n",
            "|  name|section|marks|days_present|\n",
            "+------+-------+-----+------------+\n",
            "|  Amit|   10-A|   89|          24|\n",
            "|Anjali|   10-A|   78|          20|\n",
            "| Kavya|   10-B|   92|          22|\n",
            "| Rohit|   10-B|   85|          25|\n",
            "| Sneha|   10-C|   80|          19|\n",
            "+------+-------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column: attendance_rate = days_present / 25 .\n",
        "df_attendance_rate = df_joined.withColumn('attendance_rate',col('days_present')/25)\n",
        "df_attendance_rate.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPUA-8ZqcaV9",
        "outputId": "747cac7a-9888-442e-c932-4797637ee226"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+\n",
            "|  name|section|marks|days_present|attendance_rate|\n",
            "+------+-------+-----+------------+---------------+\n",
            "|  Amit|   10-A|   89|          24|           0.96|\n",
            "|Anjali|   10-A|   78|          20|            0.8|\n",
            "| Kavya|   10-B|   92|          22|           0.88|\n",
            "| Rohit|   10-B|   85|          25|            1.0|\n",
            "| Sneha|   10-C|   80|          19|           0.76|\n",
            "+------+-------+-----+------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grade students using when :\n",
        "# A: >90, B: 80–90, C: <80.\n",
        "df_grade = df_attendance_rate.withColumn('grade',when(col(\"marks\") > 90, \"A\").when((col(\"marks\") >= 80) & (col(\"marks\") <= 90), \"B\").otherwise(\"C\"))\n",
        "df_grade.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrE6NNC_c4EE",
        "outputId": "2a6293b5-dc48-4df1-a324-42231a45fd93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  name|section|marks|days_present|attendance_rate|grade|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "|  Amit|   10-A|   89|          24|           0.96|    B|\n",
            "|Anjali|   10-A|   78|          20|            0.8|    C|\n",
            "| Kavya|   10-B|   92|          22|           0.88|    A|\n",
            "| Rohit|   10-B|   85|          25|            1.0|    B|\n",
            "| Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+------+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter students with good grades but poor attendance (<80%).\n",
        "df_filter = df_grade.filter(((col(\"grade\") == \"A\") | (col(\"grade\") == \"B\")) & (col(\"attendance_rate\") < 0.8))\n",
        "df_filter.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYAr_puFdgXX",
        "outputId": "75644321-f7ac-4c64-9247-735ba9f671b6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| name|section|marks|days_present|attendance_rate|grade|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "|Sneha|   10-C|   80|          19|           0.76|    B|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 4: Ingest CSV & JSON, Save to Parquet"
      ],
      "metadata": {
        "id": "YSSHxxJEehSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"\"\"emp_id,name,dept,city,salary\n",
        "101,Anil,IT,Bangalore,80000\n",
        "102,Kiran,HR,Mumbai,65000\n",
        "103,Deepa,Finance,Chennai,72000\"\"\"\n",
        "with open('emp.csv','w') as f:\n",
        "  f.write(data)"
      ],
      "metadata": {
        "id": "BdI4B2_nef-z"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json_data = \"\"\"{\n",
        "\"id\": 201,\n",
        "\"name\": \"Nandini\",\n",
        "\"contact\": {\n",
        "\"email\": \"nandi@example.com\",\n",
        "\"city\": \"Hyderabad\"\n",
        "},\n",
        "\"skills\": [\"Python\", \"Spark\", \"SQL\"]\n",
        "}\"\"\"\n",
        "with open('employee.json','w') as f:\n",
        "  f.write(json_data)"
      ],
      "metadata": {
        "id": "IkBFXIrOfQD7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read both formats into DataFrames.\n",
        "emp_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"emp.csv\")\n",
        "emp_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zNqqwz6feN_",
        "outputId": "16c46694-a2ce-4eae-acf1-ac408f1286f7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+---------+------+\n",
            "|emp_id| name|   dept|     city|salary|\n",
            "+------+-----+-------+---------+------+\n",
            "|   101| Anil|     IT|Bangalore| 80000|\n",
            "|   102|Kiran|     HR|   Mumbai| 65000|\n",
            "|   103|Deepa|Finance|  Chennai| 72000|\n",
            "+------+-----+-------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_df = spark.read.option(\"multiline\", \"true\").json(\"employee.json\")\n",
        "json_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwqRFqFwfmJO",
        "outputId": "697ef14c-7a56-4258-bf4d-4db2c368eb8c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---+-------+--------------------+\n",
            "|             contact| id|   name|              skills|\n",
            "+--------------------+---+-------+--------------------+\n",
            "|{Hyderabad, nandi...|201|Nandini|[Python, Spark, SQL]|\n",
            "+--------------------+---+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten nested JSON using select , col , alias , explode .\n",
        "from pyspark.sql.functions import col, explode\n",
        "flat_df = json_df.select(col(\"id\"),col(\"name\"),col(\"contact.email\").alias(\"email\"),col(\"contact.city\").alias(\"city\"),explode(col(\"skills\")).alias(\"skill\"))\n",
        "flat_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmBAKaXIgQF6",
        "outputId": "5fa763de-cb94-454b-a05a-d53bf6091f60"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------+-----------------+---------+------+\n",
            "| id|   name|            email|     city| skill|\n",
            "+---+-------+-----------------+---------+------+\n",
            "|201|Nandini|nandi@example.com|Hyderabad|Python|\n",
            "|201|Nandini|nandi@example.com|Hyderabad| Spark|\n",
            "|201|Nandini|nandi@example.com|Hyderabad|   SQL|\n",
            "+---+-------+-----------------+---------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save both as Parquet files partitioned by city.\n",
        "emp_df.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"output/emp_parquet/\")\n",
        "flat_df.write.mode(\"overwrite\").partitionBy(\"city\").parquet(\"output/json_parquet/\")"
      ],
      "metadata": {
        "id": "Nnla0bOrgiZT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 5: Spark SQL with Temp Views"
      ],
      "metadata": {
        "id": "bCPx1xWvgsMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the students DataFrame as students_view .\n",
        "df_grade.createOrReplaceTempView('students_view')"
      ],
      "metadata": {
        "id": "ErMrKToagwyG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a) Average marks per section\n",
        "spark.sql(\"select section, avg(marks) as avg_mark from students_view group by section order by section\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyZH5vMkheEM",
        "outputId": "2126070f-52e0-479d-be9e-fa118f31ec60"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------+\n",
            "|section|avg_mark|\n",
            "+-------+--------+\n",
            "|   10-A|    83.5|\n",
            "|   10-B|    88.5|\n",
            "|   10-C|    80.0|\n",
            "+-------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# b) Top scorer in each section\n",
        "spark.sql(\"select section, name, marks from students_view where (section, marks) in (select section , max(marks) from students_view group by section)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xnGqi3xiOvI",
        "outputId": "1df41360-996c-43b5-b2a7-a362bcdddd4b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----+\n",
            "|section| name|marks|\n",
            "+-------+-----+-----+\n",
            "|   10-A| Amit|   89|\n",
            "|   10-B|Kavya|   92|\n",
            "|   10-C|Sneha|   80|\n",
            "+-------+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c) Count of students in each grade category\n",
        "spark.sql(\"select grade, count(*) as students_count from students_view group by grade order by grade\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldp46KwSjQGC",
        "outputId": "c5bb3dbe-f28f-48f1-98f5-71dda8c2de90"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+--------------+\n",
            "|grade|students_count|\n",
            "+-----+--------------+\n",
            "|    A|             1|\n",
            "|    B|             3|\n",
            "|    C|             1|\n",
            "+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# d) Students with marks above class average\n",
        "spark.sql(\"select * from students_view where marks > (select avg(marks) from students_view)\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFK3D-SdjfQY",
        "outputId": "cd219c4b-87e9-477e-cfb0-d857bab40a8d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| name|section|marks|days_present|attendance_rate|grade|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "| Amit|   10-A|   89|          24|           0.96|    B|\n",
            "|Kavya|   10-B|   92|          22|           0.88|    A|\n",
            "|Rohit|   10-B|   85|          25|            1.0|    B|\n",
            "+-----+-------+-----+------------+---------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# e) Attendance-adjusted performance\n",
        "spark.sql(\"select * , round(marks * attendance_rate, 2) as adjusted_score from students_view \").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di1VbfR7kGI-",
        "outputId": "9bd95c74-b00c-4a75-ed4b-1d20f1dedc54"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+-----+------------+---------------+-----+--------------+\n",
            "|  name|section|marks|days_present|attendance_rate|grade|adjusted_score|\n",
            "+------+-------+-----+------------+---------------+-----+--------------+\n",
            "|  Amit|   10-A|   89|          24|           0.96|    B|         85.44|\n",
            "|Anjali|   10-A|   78|          20|            0.8|    C|          62.4|\n",
            "| Kavya|   10-B|   92|          22|           0.88|    A|         80.96|\n",
            "| Rohit|   10-B|   85|          25|            1.0|    B|          85.0|\n",
            "| Sneha|   10-C|   80|          19|           0.76|    B|          60.8|\n",
            "+------+-------+-----+------------+---------------+-----+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 6: Partitioned Data & Incremental Loading"
      ],
      "metadata": {
        "id": "U1AWTO5IlKuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_students.write.partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "2QTkngoclMPQ"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incremental = [(\"Tejas\", \"10-A\", 91)]\n",
        "df_inc = spark.createDataFrame(incremental, [\"name\", \"section\", \"marks\"])\n",
        "df_inc.write.mode(\"append\").partitionBy(\"section\").parquet(\"output/students/\")"
      ],
      "metadata": {
        "id": "Z_o0UeP2mFlQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List files in output/students/ using Python.\n",
        "df_all = spark.read.parquet(\"output/students/\")\n",
        "df_all.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN9WtOxCmIcG",
        "outputId": "fa361b49-045b-4b9a-f9a0-9db2cd357177"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+\n",
            "|  name|marks|section|\n",
            "+------+-----+-------+\n",
            "|Anjali|   78|   10-A|\n",
            "| Tejas|   91|   10-A|\n",
            "| Rohit|   85|   10-B|\n",
            "| Kavya|   92|   10-B|\n",
            "| Sneha|   80|   10-C|\n",
            "|  Amit|   89|   10-A|\n",
            "+------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read only partition 10-A and list students.\n",
        "df_section = spark.read.parquet(\"output/students/section=10-A\")\n",
        "df_section.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhGyzXdRmb7n",
        "outputId": "ebbabb83-f02c-49e0-9f97-092f884b2b39"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|  name|marks|\n",
            "+------+-----+\n",
            "|Anjali|   78|\n",
            "| Tejas|   91|\n",
            "|  Amit|   89|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare before/after counts for section 10-A .\n",
        "before_count = df_students.filter(\"section = '10-A'\").count()\n",
        "after_count = df_all.filter(\"section = '10-A'\").count()\n",
        "print(f\"Before: {before_count} students in 10-A\")\n",
        "print(f\"After: {after_count} students in 10-A\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyXjkBFBm0iP",
        "outputId": "14fa272e-0640-4c2c-c9ba-fa05b6d41edc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 2 students in 10-A\n",
            "After: 3 students in 10-A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Module 7: ETL Pipeline – End to End"
      ],
      "metadata": {
        "id": "Xc7cPD4ungIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = \"\"\"emp_id,name,dept,salary,bonus\n",
        "1,Arjun,IT,75000,5000\n",
        "2,Kavya,HR,62000,\n",
        "3,Sneha,Finance,68000,4000,\n",
        "4,Ramesh,Sales,58000\"\"\"\n",
        "with open('emp.csv','w') as f:\n",
        "  f.write(data2)"
      ],
      "metadata": {
        "id": "h2UkZu12neZL"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV with inferred schema.\n",
        "df = spark.read.option(\"header\", True).csv(\"emp.csv\", inferSchema=True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwaDEjspoAy_",
        "outputId": "949f7b0c-e588-4aa5-d9f5-239a31333a15"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| NULL|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| NULL|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null bonuses with 2000 .\n",
        "df = df.fillna({'bonus': 2000})\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzUo9AwsoUVo",
        "outputId": "70462e5c-716a-4449-c9bf-62a1ced01607"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+\n",
            "|emp_id|  name|   dept|salary|bonus|\n",
            "+------+------+-------+------+-----+\n",
            "|     1| Arjun|     IT| 75000| 5000|\n",
            "|     2| Kavya|     HR| 62000| 2000|\n",
            "|     3| Sneha|Finance| 68000| 4000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|\n",
            "+------+------+-------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create total_ctc = salary + bonus .\n",
        "df = df.withColumn('total_ctc', col('salary') + col('bonus'))\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymzoCX1zoenx",
        "outputId": "e6a9dc67-6712-46eb-80de-2d1ef34c95e4"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-------+------+-----+---------+\n",
            "|emp_id|  name|   dept|salary|bonus|total_ctc|\n",
            "+------+------+-------+------+-----+---------+\n",
            "|     1| Arjun|     IT| 75000| 5000|    80000|\n",
            "|     2| Kavya|     HR| 62000| 2000|    64000|\n",
            "|     3| Sneha|Finance| 68000| 4000|    72000|\n",
            "|     4|Ramesh|  Sales| 58000| 2000|    60000|\n",
            "+------+------+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter employees with total_ctc > 65000 .\n",
        "df_filter = df.filter(col(\"total_ctc\") > 65000)\n",
        "df_filter.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo0GOLflolxZ",
        "outputId": "d74b5343-5e75-4568-dc49-bb2f1a348cbe"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+-------+------+-----+---------+\n",
            "|emp_id| name|   dept|salary|bonus|total_ctc|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "|     1|Arjun|     IT| 75000| 5000|    80000|\n",
            "|     3|Sneha|Finance| 68000| 4000|    72000|\n",
            "+------+-----+-------+------+-----+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save result in:\n",
        "# JSON format.\n",
        "df_filter.write.mode(\"overwrite\").json(\"output/emp_json\")\n",
        "# Parquet format partitioned by department.\n",
        "df_filter.write.mode(\"overwrite\").partitionBy(\"dept\").parquet(\"output/emp_parquet\")"
      ],
      "metadata": {
        "id": "6_xDKHRpos8F"
      },
      "execution_count": 65,
      "outputs": []
    }
  ]
}