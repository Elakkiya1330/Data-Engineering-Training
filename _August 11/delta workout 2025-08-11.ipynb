{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "366df999-056e-412e-8d61-bb0530e40e9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will store data in:\nLanding Orders folder:    dbfs:/FileStore/tables/dlt/landing/orders\nLanding Customers folder: dbfs:/FileStore/tables/dlt/landing/customers\nSilver Delta folder:      dbfs:/tmp/delta/sil_orders\nSQL Table name:           sil_orders_tbl\n"
     ]
    }
   ],
   "source": [
    "# STEP 0 — Setup\n",
    "# These variables store the paths for each stage of the pipeline\n",
    "\n",
    "# Landing folders: raw files exactly as they arrive\n",
    "LANDING_ORDERS    = \"dbfs:/FileStore/tables/dlt/landing/orders\"\n",
    "LANDING_CUSTOMERS = \"dbfs:/FileStore/tables/dlt/landing/customers\"\n",
    "\n",
    "# Silver folder: cleaned data in Delta format\n",
    "DELTA_SILVER_PATH = \"dbfs:/tmp/delta/sil_orders\"\n",
    "\n",
    "# SQL table name pointing to the silver Delta folder\n",
    "DELTA_TABLE_NAME  = \"sil_orders_tbl\"\n",
    "\n",
    "print(\"We will store data in:\")\n",
    "print(f\"Landing Orders folder:    {LANDING_ORDERS}\")\n",
    "print(f\"Landing Customers folder: {LANDING_CUSTOMERS}\")\n",
    "print(f\"Silver Delta folder:      {DELTA_SILVER_PATH}\")\n",
    "print(f\"SQL Table name:           {DELTA_TABLE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f096b24e-6e1a-4fca-9138-ab4bf5d4fdbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Seeding inline data to landing (JSON) ...\n✅ Seeded landing JSON:\n  dbfs:/FileStore/tables/dlt/landing/orders\n  dbfs:/FileStore/tables/dlt/landing/customers\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "print(\"STEP 1: Seeding inline data to landing (JSON) ...\")\n",
    "\n",
    "orders_rows = [\n",
    "    (1, \"C001\", \"2025-08-08 09:00:00\", 12000, \"placed\"),\n",
    "    (2, \"C002\", \"2025-08-08 09:05:00\",  4500, \"placed\"),\n",
    "    (3, \"C001\", \"2025-08-08 09:10:00\", 22000, \"cancelled\"),\n",
    "    (4, \"C003\", \"2025-08-08 09:15:00\",   800, \"placed\")\n",
    "]\n",
    "customers_rows = [\n",
    "    (\"C001\", \"Ananya\", \"Bengaluru\"),\n",
    "    (\"C002\", \"Rahul\",  \"Hyderabad\"),\n",
    "    (\"C003\", \"Meera\",  \"Pune\")\n",
    "]\n",
    "\n",
    "orders_schema = T.StructType([\n",
    "    T.StructField(\"order_id\",    T.IntegerType()),\n",
    "    T.StructField(\"customer_id\", T.StringType()),\n",
    "    T.StructField(\"order_ts\",    T.StringType()),\n",
    "    T.StructField(\"amount\",      T.IntegerType()),\n",
    "    T.StructField(\"status\",      T.StringType())\n",
    "])\n",
    "cust_schema = T.StructType([\n",
    "    T.StructField(\"customer_id\", T.StringType()),\n",
    "    T.StructField(\"name\",        T.StringType()),\n",
    "    T.StructField(\"city\",        T.StringType())\n",
    "])\n",
    "\n",
    "orders_df = (spark.createDataFrame(orders_rows, orders_schema)\n",
    "             .withColumn(\"order_ts\", F.to_timestamp(\"order_ts\")))\n",
    "customers_df = spark.createDataFrame(customers_rows, cust_schema)\n",
    "\n",
    "orders_df.write.mode(\"overwrite\").json(LANDING_ORDERS)\n",
    "customers_df.write.mode(\"overwrite\").json(LANDING_CUSTOMERS)\n",
    "\n",
    "print(\"✅ Seeded landing JSON:\")\n",
    "print(f\"  {LANDING_ORDERS}\")\n",
    "print(f\"  {LANDING_CUSTOMERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b46f4a13-1d22-49dc-99c0-2a4b8d3699d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 print raw data-bronze data\nraw orders schema and sample\nroot\n |-- amount: long (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- order_id: long (nullable = true)\n |-- order_ts: string (nullable = true)\n |-- status: string (nullable = true)\n\n+------+-----------+--------+--------------------+---------+\n|amount|customer_id|order_id|            order_ts|   status|\n+------+-----------+--------+--------------------+---------+\n| 22000|       C001|       3|2025-08-08T09:10:...|cancelled|\n| 12000|       C001|       1|2025-08-08T09:00:...|   placed|\n|  4500|       C002|       2|2025-08-08T09:05:...|   placed|\n|   800|       C003|       4|2025-08-08T09:15:...|   placed|\n+------+-----------+--------+--------------------+---------+\n\nraw customers and sampe\nroot\n |-- city: string (nullable = true)\n |-- customer_id: string (nullable = true)\n |-- name: string (nullable = true)\n\n+---------+-----------+------+\n|     city|customer_id|  name|\n+---------+-----------+------+\n|Bengaluru|       C001|Ananya|\n|Hyderabad|       C002| Rahul|\n|     Pune|       C003| Meera|\n+---------+-----------+------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"step 2 print raw data-bronze data\")\n",
    "bronze_orders = spark.read.json(LANDING_ORDERS)\n",
    "bronze_customers = spark.read.json(LANDING_CUSTOMERS)\n",
    "\n",
    "print(\"raw orders schema and sample\")\n",
    "bronze_orders.printSchema()\n",
    "bronze_orders.show()\n",
    "\n",
    "print(\"raw customers and sampe\")\n",
    "bronze_customers.printSchema()\n",
    "bronze_customers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a8f4cd-9f91-4d8d-9e21-5e10782583c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote silver orders to delta\ndbfs:/tmp/delta/sil_orders\nreading back from delta silver path\n+--------+-----------+--------------------+------+---------+\n|order_id|customer_id|            order_ts|amount|   status|\n+--------+-----------+--------------------+------+---------+\n|       3|       C001|2025-08-08T09:10:...| 22000|cancelled|\n|       1|       C001|2025-08-08T09:00:...| 12000|   placed|\n|       4|       C003|2025-08-08T09:15:...|   800|   placed|\n|       2|       C002|2025-08-08T09:05:...|  4500|   placed|\n+--------+-----------+--------------------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "sil_orders = bronze_orders.select(\"order_id\", \"customer_id\", \"order_ts\", \"amount\", \"status\").filter(\"order_id is not null and amount > 0\")\n",
    "sil_orders.write.format(\"delta\").mode(\"overwrite\").save(DELTA_SILVER_PATH)\n",
    "print(\"wrote silver orders to delta\")\n",
    "print(f\"{DELTA_SILVER_PATH}\")\n",
    "print(\"reading back from delta silver path\")\n",
    "spark.read.format(\"delta\").load(DELTA_SILVER_PATH).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4750b46-4de7-4188-a80b-3eb39ab2ae24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold enriched orders by joining with customers\ngold enriched sample\n+-----------+--------+--------------------+------+---------+---------+------+\n|customer_id|order_id|            order_ts|amount|   status|     city|  name|\n+-----------+--------+--------------------+------+---------+---------+------+\n|       C001|       3|2025-08-08T09:10:...| 22000|cancelled|Bengaluru|Ananya|\n|       C001|       1|2025-08-08T09:00:...| 12000|   placed|Bengaluru|Ananya|\n|       C003|       4|2025-08-08T09:15:...|   800|   placed|     Pune| Meera|\n|       C002|       2|2025-08-08T09:05:...|  4500|   placed|Hyderabad| Rahul|\n+-----------+--------+--------------------+------+---------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "print(\"gold enriched orders by joining with customers\")\n",
    "sil_orders_df = spark.read.format(\"delta\").load(DELTA_SILVER_PATH)\n",
    "gold_enriched = (sil_orders_df.alias(\"o\").join(bronze_customers.alias(\"c\"), on = \"customer_id\", how = \"left\"))\n",
    "print(\"gold enriched sample\")\n",
    "gold_enriched.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58deff1f-4bbc-4dc7-beb9-5302461b8490",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+------+---------+\n|order_id|customer_id|            order_ts|amount|   status|\n+--------+-----------+--------------------+------+---------+\n|       1|       C001|2025-08-08T09:00:...| 12000|cancelled|\n|       3|       C001|2025-08-08T09:10:...| 22000|cancelled|\n|       4|       C003|2025-08-08T09:15:...|   800|   placed|\n|       2|       C002|2025-08-08T09:05:...|  4500|   placed|\n+--------+-----------+--------------------+------+---------+\n\n+--------+-----------+--------------------+------+---------+\n|order_id|customer_id|            order_ts|amount|   status|\n+--------+-----------+--------------------+------+---------+\n|       1|       C001|2025-08-08T09:00:...| 12000|cancelled|\n|       3|       C001|2025-08-08T09:10:...| 22000|cancelled|\n|       2|       C002|2025-08-08T09:05:...|  4500|   placed|\n+--------+-----------+--------------------+------+---------+\n\n+--------+-----------+--------------------+------+---------+\n|order_id|customer_id|            order_ts|amount|   status|\n+--------+-----------+--------------------+------+---------+\n|       1|       C001|2025-08-08T09:00:...| 12000|cancelled|\n|       3|       C001|2025-08-08T09:10:...| 22000|cancelled|\n|       2|       C002|2025-08-08T09:05:...|  4500|   placed|\n+--------+-----------+--------------------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# update, delete and upsert operations\n",
    "from pyspark.sql.functions import col\n",
    "from delta.tables import DeltaTable\n",
    "delta_Table = DeltaTable.forPath(spark, DELTA_SILVER_PATH)\n",
    "delta_Table.update(\n",
    "   condition= col('order_id') == 1,\n",
    "   set = {\"status\": \"'cancelled'\"}\n",
    ")\n",
    "delta_Table.toDF().show()\n",
    "delta_Table.delete(condition = \"order_id = 4\")\n",
    "delta_Table.toDF().show()\n",
    "delta_Table.alias(\"t\").merge(\n",
    "    gold_enriched.alias(\"s\"),\n",
    "    \"t.order_id = s.order_id\"\n",
    ").whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "delta_Table.toDF().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "delta workout 2025-08-11",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}