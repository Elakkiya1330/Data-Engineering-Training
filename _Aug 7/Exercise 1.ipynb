{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6099ecc-7c0c-4e01-9ecf-74a5a19683df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- product_id: integer (nullable = true)\n |-- product_name: string (nullable = true)\n |-- category: string (nullable = true)\n |-- price: integer (nullable = true)\n |-- quantity: integer (nullable = true)\n\n+----------+------------+-----------+-----+--------+\n|product_id|product_name|   category|price|quantity|\n+----------+------------+-----------+-----+--------+\n|       101|      Laptop|Electronics|55000|      10|\n|       102|  Smartphone|Electronics|30000|      25|\n|       103|       Chair|  Furniture| 2500|      50|\n|       104|        Book| Stationery|  400|     200|\n|       105|  Headphones|Electronics| 1500|     100|\n|       106|       Table|  Furniture| 3200|      40|\n|       107|         Pen| Stationery|   20|     500|\n|       108|     Monitor|Electronics|12000|      15|\n|       109|    Notebook| Stationery|   60|     300|\n|       110|        Sofa|  Furniture|45000|       5|\n+----------+------------+-----------+-----+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# 1. Read the above data from CSV into a DataFrame and print the schema.\n",
    "df_csv = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"dbfs:/FileStore/tables/products.csv\")\n",
    "df_csv.printSchema()\n",
    "df_csv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f13d654-cc06-44c7-9fa9-25490d4e8563",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- category: string (nullable = true)\n |-- price: long (nullable = true)\n |-- product_id: long (nullable = true)\n |-- product_name: string (nullable = true)\n |-- quantity: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# 2. Read the same data from JSON and compare with the CSV schema. Any differences?\n",
    "# read json\n",
    "df_json = spark.read.json('dbfs:/FileStore/tables/products.json')\n",
    "df_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d583d339-c67f-4131-8882-7d36e74d1572",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 3. Convert the CSV data into Parquet format and save to disk.\n",
    "# read parquet\n",
    "df_csv.write.mode('overwrite').parquet('dbfs:/tmp/product_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcb5f3b4-077b-4588-a7d1-6b88186cf4a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV size: 362 bytes\nJSON size: 955 bytes\nParquet size: 223 bytes\nSmallest format: Parquet with size 223 bytes\n"
     ]
    }
   ],
   "source": [
    "# 4. Measure the size of CSV vs JSON vs Parquet on disk. Which one is smallest?\n",
    "csv_size = dbutils.fs.ls(\"dbfs:/FileStore/tables/products.csv\")[0].size\n",
    "json_size = dbutils.fs.ls(\"dbfs:/FileStore/tables/products.json\")[0].size\n",
    "parquet_size = dbutils.fs.ls(\"dbfs:/tmp/product_data.parquet\")[0].size\n",
    "\n",
    "print(f\"CSV size: {csv_size} bytes\")\n",
    "print(f\"JSON size: {json_size} bytes\")\n",
    "print(f\"Parquet size: {parquet_size} bytes\")\n",
    "\n",
    "sizes = {\"CSV\": csv_size, \"JSON\": json_size, \"Parquet\": parquet_size}\n",
    "smallest = min(sizes, key=sizes.get)\n",
    "print(f\"Smallest format: {smallest} with size {sizes[smallest]} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82a34253-8380-415b-877b-123b487a15fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-----+--------+-------------+----------+\n|product_id|product_name|   category|price|quantity|Total_revenue|price_band|\n+----------+------------+-----------+-----+--------+-------------+----------+\n|       101|      Laptop|Electronics|55000|      10|       550000|      High|\n|       102|  Smartphone|Electronics|30000|      25|       750000|      High|\n|       103|       Chair|  Furniture| 2500|      50|       125000|       Low|\n|       104|        Book| Stationery|  400|     200|        80000|       Low|\n|       105|  Headphones|Electronics| 1500|     100|       150000|       Low|\n|       106|       Table|  Furniture| 3200|      40|       128000|    Medium|\n|       107|         Pen| Stationery|   20|     500|        10000|       Low|\n|       108|     Monitor|Electronics|12000|      15|       180000|      High|\n|       109|    Notebook| Stationery|   60|     300|        18000|       Low|\n|       110|        Sofa|  Furniture|45000|       5|       225000|      High|\n+----------+------------+-----------+-----+--------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 5. Add a column total_revenue = price * quantity for each record.\n",
    "csv_df = df.withColumn('Total_revenue', df['price'] * df['quantity'])\n",
    "csv_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "895cba24-0563-4c52-abda-91c753ad135e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-----+--------+-------------+----------+\n|product_id|product_name|   category|price|quantity|Total_revenue|price_band|\n+----------+------------+-----------+-----+--------+-------------+----------+\n|       102|  Smartphone|Electronics|30000|      25|       750000|      High|\n|       101|      Laptop|Electronics|55000|      10|       550000|      High|\n|       110|        Sofa|  Furniture|45000|       5|       225000|      High|\n+----------+------------+-----------+-----+--------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 6. Find the top 3 products with the highest total revenue.\n",
    "from pyspark.sql.functions import col\n",
    "csv_df.orderBy(col(\"total_revenue\").desc()).limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaf75058-fc5b-4a84-877b-325f0aeb244d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+-----+--------+-------------+----------+\n|product_id|product_name| category|price|quantity|Total_revenue|price_band|\n+----------+------------+---------+-----+--------+-------------+----------+\n|       106|       Table|Furniture| 3200|      40|       128000|    Medium|\n|       110|        Sofa|Furniture|45000|       5|       225000|      High|\n+----------+------------+---------+-----+--------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 7. Filter and display only Furniture products with price > 3000.\n",
    "csv_df.filter((col('category') == 'Furniture') & (col('price') > 3000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f32e6fff-b624-4f4d-a9b1-5f15b859caa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+-----------+-----+--------+-------------+----------+\n|product_id|product_name|   category|price|quantity|Total_revenue|price_band|\n+----------+------------+-----------+-----+--------+-------------+----------+\n|       101|      Laptop|Electronics|55000|      10|       550000|      High|\n|       102|  Smartphone|Electronics|30000|      25|       750000|      High|\n|       103|       Chair|  Furniture| 2500|      50|       125000|       Low|\n|       104|        Book| Stationery|  400|     200|        80000|       Low|\n|       105|  Headphones|Electronics| 1500|     100|       150000|       Low|\n|       106|       Table|  Furniture| 3200|      40|       128000|    Medium|\n|       107|         Pen| Stationery|   20|     500|        10000|       Low|\n|       108|     Monitor|Electronics|12000|      15|       180000|      High|\n|       109|    Notebook| Stationery|   60|     300|        18000|       Low|\n|       110|        Sofa|  Furniture|45000|       5|       225000|      High|\n+----------+------------+-----------+-----+--------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 8. Create a new column price_band with values:\n",
    "# 'High' if price > 10000\n",
    "# 'Medium' if 3000 < price <= 10000\n",
    "# 'Low' if price ≤ 3000\n",
    "from pyspark.sql.functions import when\n",
    "csv_df.withColumn(\"price_band\",when(col(\"price\") > 10000, \"High\").when((col(\"price\") > 3000) & (col(\"price\") <= 10000), \"Medium\").otherwise(\"Low\")\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80fbf006-dcba-4fed-9e48-892f843d6f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n|   category|total_quantity|\n+-----------+--------------+\n|Electronics|           150|\n| Stationery|          1000|\n|  Furniture|            95|\n+-----------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 9. Group by category and calculate total quantity sold.\n",
    "from pyspark.sql.functions import sum\n",
    "csv_df.groupBy(\"category\").agg(sum(\"quantity\").alias(\"total_quantity\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e14673-6e57-4ef8-8f34-6944d14c8e1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n|   category|avg_price|\n+-----------+---------+\n|Electronics|  24625.0|\n| Stationery|    160.0|\n|  Furniture|  16900.0|\n+-----------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# 10. Calculate average price of products for each category.\n",
    "from pyspark.sql.functions import avg\n",
    "csv_df.groupBy(\"category\").agg(avg(\"price\").alias(\"avg_price\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a78e4e8-0443-47f8-bba9-4b97adbff972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n|price_band|count|\n+----------+-----+\n|      High|    4|\n|       Low|    5|\n|    Medium|    1|\n+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "# 11. Count how many products fall in each price_band .\n",
    "csv_df.groupBy(\"price_band\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49d46d7c-cfdd-4958-9954-f73213c2fd04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 12. Write the filtered Electronics products (price > 5000) into a Parquet file.\n",
    "elect_filter = csv_df.filter((col('category') == 'Electronics') & (col('price') > 5000) )\n",
    "elect_filter.write.mode('overwrite').parquet('dbfs:/tmp/product_data_electronics.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4264a8b4-8251-4a54-9044-f6199a481e83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 13. Write the Stationery products into a JSON file.\n",
    "stationery_filter = csv_df.filter((col('category') == 'Stationery'))\n",
    "stationery_filter.write.mode('overwrite').json('dbfs:/tmp/product_data_stationery.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c01fbcb6-adfd-409b-9b98-214900ea8afe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n|   category|total_revenue|\n+-----------+-------------+\n|Electronics|      1480000|\n+-----------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "# 14. Load Parquet back and run a query to find which category has highest total revenue.\n",
    "elect_df = spark.read.parquet('dbfs:/tmp/product_data_electronics.parquet')\n",
    "elect_df.groupBy(\"category\").agg(sum(\"Total_revenue\").alias(\"total_revenue\")).orderBy(col(\"total_revenue\").desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "455f65fe-cb2e-4d9a-bf3f-a69df1c63fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+----------+-----+--------+-------------+----------+\n|product_id|product_name|  category|price|quantity|Total_revenue|price_band|\n+----------+------------+----------+-----+--------+-------------+----------+\n|       104|        Book|Stationery|  400|     200|        80000|       Low|\n|       107|         Pen|Stationery|   20|     500|        10000|       Low|\n|       109|    Notebook|Stationery|   60|     300|        18000|       Low|\n+----------+------------+----------+-----+--------+-------------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "# 15. BONUS: Create a temporary view from the DataFrame and run Spark SQL to find all products with quantity > 100 and price < 1000.\n",
    "df.createOrReplaceTempView(\"product_data\")\n",
    "spark.sql(\"select * from product_data where quantity > 100 AND price < 1000\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Exercise 1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}